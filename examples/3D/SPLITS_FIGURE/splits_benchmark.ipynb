{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff99ebb2-9532-469b-ac2d-60b8256a66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tifffile import imread\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Union\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "from benchmark_instance import plot_performance, plot_stat_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef328ed8-8c67-4666-b6f9-b546d58e1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    ") -> np.float64:\n",
    "    \"\"\"Compute Dice-Sorensen coefficient between two numpy arrays\n",
    "    Args:\n",
    "        y_true: Ground truth label\n",
    "        y_pred: Prediction label\n",
    "    Returns: dice coefficient\n",
    "    \"\"\"\n",
    "    sum_tensor = np.sum\n",
    "    smooth = 1.0\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = sum_tensor(y_true_f * y_pred_f)\n",
    "    score = (2.0 * intersection + smooth) / (\n",
    "        sum_tensor(y_true_f) + sum_tensor(y_pred_f) + smooth\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def intersection_over_union(\n",
    "    y_true: np.ndarray, y_pred: np.ndarray\n",
    ") -> np.float64:\n",
    "    \"\"\"Compute Intersection over Union between two numpy arrays\n",
    "    Args:\n",
    "        y_true: Ground truth label\n",
    "        y_pred: Prediction label\n",
    "    Returns: IoU\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def precision(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "    \"\"\"Compute precision between two numpy arrays\n",
    "    Args:\n",
    "        y_true: Ground truth label\n",
    "        y_pred: Prediction label\n",
    "    Returns: precision\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return intersection / np.sum(y_pred_f)\n",
    "\n",
    "\n",
    "def recall(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "    \"\"\"Compute recall between two numpy arrays\n",
    "    Args:\n",
    "        y_true: Ground truth label\n",
    "        y_pred: Prediction label\n",
    "    Returns: recall\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return intersection / np.sum(y_true_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a145af40-447d-42b4-a8c8-466395e15718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance_semantic(\n",
    "    image, gt, name, threshold_range=None, print_max=True\n",
    "):\n",
    "    \"\"\"Plot the Dice, IoU, precision and recall for a given model and threshold range, across the specified threshold range between 0 and 1\"\"\"\n",
    "    if threshold_range is None:\n",
    "        threshold_range = np.arange(0, 1, 0.025)\n",
    "\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    for threshold in threshold_range:\n",
    "        pred = np.where(image > threshold, 1, 0)\n",
    "        dice_scores.append(dice_coeff(gt, pred))\n",
    "        iou_scores.append(intersection_over_union(gt, pred))\n",
    "        precision_scores.append(precision(gt, pred))\n",
    "        recall_scores.append(recall(gt, pred))\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(threshold_range, dice_scores, label=\"Dice\")\n",
    "    plt.plot(threshold_range, iou_scores, label=\"IoU\")\n",
    "    plt.plot(threshold_range, precision_scores, label=\"Precision\")\n",
    "    plt.plot(threshold_range, recall_scores, label=\"Recall\")\n",
    "    # draw optimal threshold at max Dice score\n",
    "    optimal_threshold = threshold_range[np.argmax(dice_scores)]\n",
    "    plt.axvline(optimal_threshold, color=\"black\", linestyle=\"--\")\n",
    "    # label line as optimal threshold at the bottom\n",
    "    plt.text(\n",
    "        optimal_threshold - 0.25,\n",
    "        0,\n",
    "        f\"Max Dice @ {optimal_threshold:.2f}\",\n",
    "        verticalalignment=\"bottom\",\n",
    "    )\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Model performance for {name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    if print_max:\n",
    "        print(\n",
    "            f\"Max Dice of {np.max(dice_scores):.2f} @ {threshold_range[np.argmax(dice_scores)]:.2f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Max IoU of {np.max(iou_scores):.2f} @ {threshold_range[np.argmax(iou_scores)]:.2f}\"\n",
    "        )\n",
    "\n",
    "    return dice_scores, iou_scores, precision_scores, recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c84592-b72d-4c86-ae83-c1120ed9078e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
